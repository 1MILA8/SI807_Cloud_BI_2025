# 1. CreaciÃ³n del Proyecto

Se creÃ³ un proyecto independiente en Google Cloud Platform para aislar todos los recursos de la prÃ¡ctica, evitando contaminaciones con otros proyectos personales o institucionales.

## ğŸ›‚ 2. GestiÃ³n de Identidades y Accesos (IAM)

Se aplicÃ³ el principio de mÃ­nimo privilegio, asignando permisos Ãºnicamente segÃºn las funciones tÃ©cnicas del flujo de datos. Cada rol fue otorgado vÃ­a CLI usando gcloud, garantizando trazabilidad.

![Ingresar_IAM](Evidencias/2_Input_IAM.png)

### âœ”ï¸ Roles tÃ©cnicos generales del proyecto

```json
gcloud projects add-iam-policy-binding grupo6-scotiabank \
  --member="serviceAccount:sbs-scraper-sa@grupo6-scotiabank.iam.gserviceaccount.com" \
  --role="roles/storage.objectCreator"

gcloud projects add-iam-policy-binding grupo6-scotiabank \
  --member="serviceAccount:75587073872-compute@developer.gserviceaccount.com" \
  --role="roles/artifactregistry.reader"

gcloud projects add-iam-policy-binding grupo6-scotiabank \
  --member="serviceAccount:service-75587073872@gcp-sa-eventarc.iam.gserviceaccount.com" \
  --role="roles/storage.objectViewer"

``` 
Servicio / Cuenta	FunciÃ³n

- storage.objectCreator:Permite carga de archivos desde scraping hacia el Data Lake

- artifactregistry.reader: Acceso a imÃ¡genes necesarias para servicios compute
storage.objectViewer	Permite lectura de objetos para flujos event-driven
## ğŸ‘¥ 3. Roles asignados segÃºn funciÃ³n en el pipeline

Asignar roles a los usuarios a travez de la linea de comandos CLI de Google Cloud Plataform

- **Cambiar en Usuario1** : PONER@USUARIO1 -> por el usuario 1 admitido
- **Cambiar en Usuario2** : PONER@USUARIO2 -> por el usuario 2 admitido

### ğŸ”¸ Rol 1 â€“ Scraping y carga de datos al Data Lake

Responsabilidades:

- ObtenciÃ³n de archivos Excel desde la web del SBS

- EjecuciÃ³n periÃ³dica del scraping

- Carga automatizada de los archivos raw a Cloud Storage

**Permisos otorgados para su actividad:**


```bash
gcloud projects add-iam-policy-binding grupo6-scotiabank --member="user:PONER@USUARIO1" --role="roles/cloudfunctions.developer" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member="user:PONER@USUARIO1" --role="roles/storage.admin" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member="user:PONER@USUARIO1" --role="roles/cloudscheduler.admin" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member="user:PONER@USUARIO1" --role="roles/iam.serviceAccountUser" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member="user:PONER@USUARIO1" --role="roles/run.admin" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member="user:PONER@USUARIO1" --role="roles/resourcemanager.projectIamAdmin"
```

â¡ï¸ Con este set, el rol puede programar, ejecutar y operar funciones serverless encargadas de capturar los datos fuente y almacenarlos en la capa bronze del Data Lake.


### ğŸ”¸ Rol 2 â€“ Procesamiento, ETL y modelado analÃ­tico

Responsabilidades:

- TransformaciÃ³n de datos con ETL

- Uso de BigQuery como repositorio analÃ­tico

- CreaciÃ³n y administraciÃ³n de datasets

- DiseÃ±o de capas Bronze, Silver (Plata) y Gold (Oro)


**Permisos otorgados:**
```bash
gcloud projects add-iam-policy-binding grupo6-scotiabank --member=user:PONER@USUARIO2 --role="roles/bigquery.dataOwner" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member=user:PONER@USUARIO2 --role="roles/cloudfunctions.developer" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member=user:PONER@USUARIO2 --role="roles/storage.admin" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member=user:PONER@USUARIO2 --role="roles/cloudscheduler.admin" && \
gcloud projects add-iam-policy-binding grupo6-scotiabank --member=user:PONER@USUARIO2 --role="roles/run.admin"
```

â¡ï¸ Este rol gobierna la evoluciÃ³n de los datos, pasando de sin procesar â†’ curados â†’ listos para explotaciÃ³n analÃ­tica.

![Respuesta_Output](Evidencias/3-Out_Put_IAM.png)


### ğŸ”¸ Cuenta de Servicio - Clave

Se creo una clave para la cuenta de servicio con el cual permitira la explotaciÃ³n analÃ­tica.

![Creacion de clave cuenta de servicio 1](Evidencias/4_Agregar_Clave.png)
![Creacion de clave cuenta de servicio 2](Evidencias/5_Escoger_formato.png)
![Creacion de clave cuenta de servicio 3](Evidencias/6_Clave_Creada.png)

Esto descargarÃ¡ y generarÃ¡ un archivo JSON con credenciales y claves que permitiran la coneccion con fuentes externar analÃ­ticas como el PowerBI

![Creacion de clave cuenta de servicio 4](Evidencias/7_Json_Vista.png)

ğŸ“˜ Puede comprobar la conexiÃ³n en [08_PowerBI](../08_PowerBI/README.md)


## ğŸ” 4. Principios de Seguridad aplicados

Se implementaron prÃ¡cticas recomendadas:

- âœ” IAM granular por funciÃ³n tÃ©cnica
- âœ” NingÃºn usuario con rol Owner
- âœ” Acceso a Storage y BigQuery controlado por capas
- âœ” Service Accounts independientes para automatizaciones
- âœ” Uso de CLI â†’ mayor auditabilidad del despliegue

![ConfiguraciÃ³n_IAM](Evidencias\1-IAM_Roles.png)

# Escalabilidad, Elasticidad y Alta Disponibilidad

## 1. ANÃLISIS DE NECESIDADES DEL PROYECTO

### CaracterÃ­sticas Actuales
- **Volumen de datos:** Archivos de MB, procesamiento mensual
- **Datos procesados:** ~400k registros (Bronze) â†’ ~4k registros (Gold)
- **Usuarios concurrentes:** MÃ¡ximo 5 usuarios en Power BI
- **Frecuencia de carga:** Mensual (SBS publica datos mensualmente)
- **Tiempo de procesamiento:** <10 minutos por job de Spark
- **Criticidad:** Dashboard de riesgo bancario (alta importancia, baja frecuencia)

### EvaluaciÃ³n de Requerimientos

| Componente | Escalabilidad | Elasticidad | Alta Disponibilidad | JustificaciÃ³n |
|------------|---------------|-------------|---------------------|---------------|
| Cloud Storage | âœ… Nativa | âœ… Serverless | âš ï¸ Implementar | Datos crÃ­ticos requieren redundancia |
| Cloud Functions | âœ… Nativa | âœ… Serverless | âœ… Multi-zona automÃ¡tica | Ya incluida por diseÃ±o |
| Dataproc | âš ï¸ Configurar | âš ï¸ Configurar | âŒ No necesario | Jobs efÃ­meros de 10 min no requieren HA |
| BigQuery | âœ… Nativa | âœ… Serverless | âš ï¸ Implementar | Datos histÃ³ricos requieren DR |
| Power BI | N/A | N/A | N/A | Gestionado externamente |

---

## 2. ESCALABILIDAD

### 2.1 Cloud Storage (Descarga SBS)
**Estado:** âœ… **ESCALABLE POR DISEÃ‘O - NO REQUIERE CONFIGURACIÃ“N ADICIONAL**

**JustificaciÃ³n:**
- Cloud Storage escala automÃ¡ticamente de bytes a petabytes
- En el caso: Archivos de MB mensuales estÃ¡n muy por debajo de lÃ­mites
- No hay configuraciÃ³n de escalabilidad necesaria

**CuÃ¡ndo SÃ serÃ­a necesario configurar:**
- Archivos >5TB que requieran particionamiento
- Ingesta de miles de archivos por segundo
- Transferencias desde mÃºltiples regiones

### 2.2 Dataproc (Procesamiento Spark)
**Estado:** âš ï¸ **CONFIGURAR AUTOSCALING HORIZONTAL**

**JustificaciÃ³n:**
- Aunque el job dura <10 min, el autoscaling optimiza costos
- Permite manejar picos si el volumen de datos crece
- Escala de 2 a N workers segÃºn necesidad

**ConfiguraciÃ³n recomendada:**
- Cluster efÃ­mero con 1 master + 2-8 workers
- Autoscaling basado en mÃ©tricas de YARN
- Preemptible workers para reducir costos 60%

### 2.3 BigQuery
**Estado:** âœ… **ESCALABLE POR DISEÃ‘O - SERVERLESS**

**JustificaciÃ³n:**
- BigQuery escala automÃ¡ticamente desde KB hasta petabytes
- En el caso: 400k registros en Bronze, 4k en Gold es minimal
- Slots on-demand escalan segÃºn la consulta
- Power BI con 5 usuarios no generarÃ¡ carga significativa

**CuÃ¡ndo SÃ necesitarÃ­as escalabilidad vertical:**
- Consultas complejas con >1TB de datos escaneados
- >100 usuarios concurrentes
- Jobs de ML intensivos en BigQuery ML

---

## 3. ELASTICIDAD (AUTOSCALING)

### 3.1 Cloud Functions (Descarga automatizada)
**Estado:** âœ… **ELÃSTICA POR DISEÃ‘O - SERVERLESS**

**JustificaciÃ³n:**
- Cloud Functions escala de 0 a miles de instancias automÃ¡ticamente
- En el caso: 1 ejecuciÃ³n mensual = 1 instancia
- Pago por uso (solo cuando se ejecuta)
- Sin configuraciÃ³n adicional necesaria

### 3.2 Dataproc Autoscaling
**Estado:** âš ï¸ **IMPLEMENTAR AUTOSCALING**

**JustificaciÃ³n PARA implementar:**
- Jobs efÃ­meros se benefician de autoscaling para optimizar tiempo/costo
- Si un mes los datos de SBS crecen 10x, el cluster se adapta
- DestrucciÃ³n automÃ¡tica despuÃ©s del job (ahorro de costos)

**ConfiguraciÃ³n:**
- Min workers: 2
- Max workers: 8
- Scale-down factor: Agresivo (job corto)
- Preemptible workers: 50% del cluster

### 3.3 BigQuery
**Estado:** âœ… **ELÃSTICO POR DISEÃ‘O**

**JustificaciÃ³n:**
- Slots on-demand se asignan dinÃ¡micamente
- Escala a 0 cuando no hay consultas
- En el caso: 5 usuarios = ~100-500 slots mÃ¡ximo
- Sin configuraciÃ³n necesaria

**CuÃ¡ndo SÃ configurarÃ­as reservations:**
- >50 usuarios concurrentes
- Consultas predecibles que requieren SLA garantizado
- Necesidad de control de costos con flat-rate pricing

---

## 4. ALTA DISPONIBILIDAD Y DISASTER RECOVERY

### 4.1 Cloud Storage
**Estado:** âš ï¸ **IMPLEMENTAR DUAL-REGIONAL**

**JustificaciÃ³n PARA implementar:**
- Datos de SBS son fuente Ãºnica de verdad
- Si se pierde el bucket, no hay forma de recuperar datos histÃ³ricos
- Cumplimiento regulatorio bancario requiere DR

**ConfiguraciÃ³n:**
- Storage Class: `STANDARD` dual-regional
- Regiones: `southamerica-east1` + `us-east1` (o `southamerica-west1` cuando estÃ© disponible)
- Versionamiento: Habilitado (recuperar archivos sobrescritos)
- Lifecycle: Mover a Nearline despuÃ©s de 90 dÃ­as

### 4.2 Cloud Functions
**Estado:** âœ… **ALTA DISPONIBILIDAD NATIVA**

**JustificaciÃ³n:**
- Cloud Functions 2nd gen se despliega automÃ¡ticamente en mÃºltiples zonas
- Si una zona falla, Cloud Run ejecuta en otra zona
- Para job mensual, la disponibilidad nativa es suficiente

**CuÃ¡ndo SÃ configurarÃ­as multi-regiÃ³n:**
- Funciones crÃ­ticas de tiempo real (no tu caso)
- APIs pÃºblicas con SLA >99.95%

### 4.3 Dataproc
**Estado:** âŒ **NO IMPLEMENTAR HA**

**JustificaciÃ³n PARA NO implementar:**
- Clusters efÃ­meros de 10 minutos no requieren HA
- Si falla un job, simplemente se re-ejecuta
- El costo de HA mode (3 masters) no se justifica
- Los datos origen (GCS) y destino (BQ) SÃ tienen HA

**CuÃ¡ndo SÃ implementarÃ­as HA mode:**
- Clusters permanentes 24/7
- Jobs crÃ­ticos de >2 horas
- HDFS con datos que no estÃ¡n en GCS

### 4.4 BigQuery
**Estado:** âš ï¸ **IMPLEMENTAR BACKUP MULTI-REGIONAL**

**JustificaciÃ³n PARA implementar:**
- Datos histÃ³ricos de riesgo bancario son crÃ­ticos
- RegulaciÃ³n financiera requiere DR (RPO/RTO bajos)
- BigQuery datasets NO se replican automÃ¡ticamente

**ConfiguraciÃ³n:**
- Dataset principal: `southamerica-east1`
- Backup dataset: `us-east1` o `EU` (multi-regional)
- Snapshots automÃ¡ticos despuÃ©s de cada carga mensual
- Retention: 12 meses mÃ­nimo

**RPO/RTO esperados:**
- RPO (Recovery Point Objective): 1 mes (Ãºltima carga)
- RTO (Recovery Time Objective): <4 horas (restaurar desde snapshot)

---

## 5. RESUMEN DE IMPLEMENTACIONES

### âœ… Implementar (Justificado)
1. **Cloud Storage Dual-Regional:** ProtecciÃ³n de datos fuente
2. **Dataproc Autoscaling:** OptimizaciÃ³n costo/performance
3. **BigQuery Backup Multi-Regional:** DR para datos histÃ³ricos
4. **Versionamiento en GCS:** RecuperaciÃ³n de archivos

### âŒ NO Implementar (Justificado)
1. **Dataproc HA Mode:** Jobs efÃ­meros no lo requieren
2. **BigQuery Reservations:** Volumen bajo, on-demand suficiente
3. **Cloud Functions Multi-RegiÃ³n:** Job mensual, HA nativa suficiente

### âš ï¸ Casos HipotÃ©ticos (Documentar cuÃ¡ndo SÃ aplicarÃ­an)
1. **Escalabilidad vertical BigQuery:** Si crece a >10M registros/dÃ­a
2. **Multi-regiÃ³n activo-activo:** Si Power BI se usa globalmente 24/7
3. **Dataproc clusters permanentes:** Si se requieren consultas interactivas

---

## 6. ARQUITECTURA RECOMENDADA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REGIÃ“N: southamerica-east1 (SÃ£o Paulo) - PRINCIPAL             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Cloud Storage (Dual-Regional)                                  â”‚
â”‚  â”œâ”€â”€ sbs-raw-data/ (Bronze source)                             â”‚
â”‚  â”‚   â”œâ”€â”€ Class: STANDARD (dual-region)                         â”‚
â”‚  â”‚   â”œâ”€â”€ Versioning: ON                                        â”‚
â”‚  â”‚   â””â”€â”€ Lifecycle: â†’ Nearline (90d)                           â”‚
â”‚  â”‚                                                              â”‚
â”‚  Cloud Functions (Multi-AZ automÃ¡tico)                          â”‚
â”‚  â”œâ”€â”€ download-sbs-monthly                                      â”‚
â”‚  â””â”€â”€ trigger-dataproc-job                                      â”‚
â”‚                                                                 â”‚
â”‚  Dataproc (Ephemeral + Autoscaling)                            â”‚
â”‚  â”œâ”€â”€ Master: n1-standard-4 (1)                                 â”‚
â”‚  â”œâ”€â”€ Workers: n1-standard-4 (2-8 autoscaling)                  â”‚
â”‚  â”œâ”€â”€ Preemptible: 50% workers                                  â”‚
â”‚  â””â”€â”€ Auto-delete: 30min after idle                             â”‚
â”‚                                                                 â”‚
â”‚  BigQuery (Serverless)                                          â”‚
â”‚  â”œâ”€â”€ Dataset: bronze_sbs (regional)                            â”‚
â”‚  â”œâ”€â”€ Dataset: silver_sbs (regional)                            â”‚
â”‚  â””â”€â”€ Dataset: gold_sbs (regional)                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REGIÃ“N: us-east1 (Carolina del Sur) - DR                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Cloud Storage (Replica dual-regional automÃ¡tica)               â”‚
â”‚                                                                 â”‚
â”‚  BigQuery Snapshots (Backup mensual)                            â”‚
â”‚  â”œâ”€â”€ Dataset: bronze_sbs_backup                                â”‚
â”‚  â”œâ”€â”€ Dataset: silver_sbs_backup                                â”‚
â”‚  â””â”€â”€ Dataset: gold_sbs_backup                                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXTERNO: Power BI (conecta via BigQuery connector)             â”‚
â”‚  â””â”€â”€ Consulta: gold_sbs.kpis_riesgo (pre-agregado)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. ESTIMACIÃ“N DE COSTOS (Mensual)

| Componente | ConfiguraciÃ³n | Costo Estimado USD |
|------------|---------------|-------------------|
| Cloud Storage Dual-Regional | 1 GB datos | $0.05 |
| Cloud Functions | 1 ejecuciÃ³n/mes | <$0.01 |
| Dataproc Autoscaling | 10 min/mes, 4 workers avg | $0.30 |
| BigQuery Storage | 1 GB | $0.02 |
| BigQuery Queries | 5 usuarios, 100 MB/dÃ­a | $0.25 |
| BigQuery Snapshots | 1 GB backup | $0.03 |
| **TOTAL** | | **~$0.65/mes** |


---

## 8. PLAN DE IMPLEMENTACIÃ“N

### Fase 1: Escalabilidad y Elasticidad (Semana 1)
- [ ] Configurar Dataproc autoscaling
- [ ] Validar autoscaling con job de prueba
- [ ] Documentar mÃ©tricas de escalado

### Fase 2: Alta Disponibilidad (Semana 2)
- [ ] Migrar Cloud Storage a dual-regional
- [ ] Habilitar versionamiento en buckets
- [ ] Configurar lifecycle policies

### Fase 3: Disaster Recovery (Semana 3)
- [ ] Crear datasets de backup en us-east1
- [ ] Automatizar snapshots de BigQuery
- [ ] Documentar procedimiento de restauraciÃ³n
- [ ] Ejecutar simulacro de DR

### Fase 4: Monitoreo (Semana 4)
- [ ] Configurar Cloud Monitoring dashboards
- [ ] Alertas para fallos en Cloud Functions
- [ ] Alertas para costos >$10/mes
- [ ] Documentar runbook de incidentes